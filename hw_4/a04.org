#+title: A04

#+LATEX_HEADER: \setcounter{tocdepth}{1}

* Git Repository
https://github.com/Willenbrink/AGP

* Exercise 1
** X=800 Y=600
There exist $\lceil 800/16 \rceil \cdot \lceil 600/16 \rceil = 50 \cdot 38 = 1900$ blocks. Each block consists of $16 \cdot 16$ threads and $16 \cdot 16 / 32 = 8$ warps as each warp consists of 32 threads.

Assuming the correct distribution of threads across the warps, none will have control divergence. As each column of threads within a block executes the same instructions, the threads must be assigned in a column-major order to the warps. In this case, the right-most blocks will have 4 warps completely within the image and 4 warps completely without.

If the assignment is done in a row-major order, all warps in the right-most column will diverge, resulting in $38 \cdot 8$ diverging warps.

** X=600 Y=800
In this case, the incomplete blocks are located in the bottom row. The reasoning is simply an inversion of the previous case. If we assume a row-major order, we will now have no diverging threads. If we assume column-major order, we will have $50 \cdot 8$ diverging warps as the complete bottom row of blocks will diverge.

** X=600 Y=799
In this case, both row-major and column-major assignments of threads to warps will result in divergence. Assuming row-major order, the blocks to the right will result in $38 \cdot 8$ divergin warps. The blocks at the bottom will not diverge at all.

* Exercise 2
The performance benefits are negligible across all relevant input sizes as the vast majority of the execution time is spent on copying.
[[./ex_2/ex1.png]]

We get almost perfect usage of the GPU by using exactly two segments. Due to their overhead, further increasing the number of segments degrades performance.
[[./ex_2/ex1_2.png]]

* Exercise 3
** What are the differences between pageable memory and pinned memory, what are the tradeoffs?
Pageable memory uses address tables to be swappable and oversubscribable. It generally gives the OS more opportunities to manage the memory as the actual address in memory is not the same as is shown to the program (i.e. virtual adresses).

Pinned memory is at a fixed location in memory and therefore is quicker to access, helping reduce memory access times.

** Compare the profiling results between your original code and the new version using pinned memory. Do you see any difference in terms of the breakdown of execution time after changing to pinned memory?
Device to Host is significantly faster. Host to Device is minimally faster. Besides that the changes are minimal.

** What is a managed memory? What are the implications of using managed memory?
Managed memory allows programmers to ignore memcpys from/to the device as Cuda automatically takes care of that. Thus, it lowers the barrier to writing simple Cuda programs.

** Compare the profiling results between your original code and the new version using managed memory. What do you observe in the profiling results?
Memcpy is no longer explicitly listed. UM results in a significant slowdown. Whereas before the GPU activies took 12ms, they now took 17ms.

* Exercise 4
I could not solve this task because I ran into a problem with the matrix-vector multiplication. Things I investigated:
- Normal execution: It throws an error at the next line (cublasDnrm2) and crashes in the thrust call.
- gdb and cuda-gdb. With gdb, no crash occurs, with cuda-gdb no backtrace is printed. Loading the coredump fails. cuda-gdb shows a CUDA_EXCEPTION_14: Warp Illegal Address. I found no problem with the allocations.
- Reading the documentation. The error code given by the next call does not match any of the possible values. Furthermore, only one algorithm (CUSPARSE_SPMV_COO_ALG2) is listed as supported. It is not clear whether this is a problem with the documentation or not.
- cuda-memcheck. Fails without information.
- Running on Google Colab. Same issue.
- Comparing with sample (https://github.com/NVIDIA/CUDALibrarySamples/blob/master/cuSPARSE/spmv_csr/spmv_csr_example.c). Executing the sample works, thereby eliminating GPU/toolchain issues. The only difference I found in the code is the usage of managed memory. Rewriting the whole program to use unmanaged memory might help. As I'm not sure if this helps and due to the large amount of effort for likely no gain I did not try this.

  Sidenote: I did not use the provided src_cpp[:exports code]{cusparseMatDescr_t Adescriptor}  and instead used src_cpp[:exports code]{cusparseSpMatDescr_t} , i.e. a sparse matrix descriptor. I think this is a mistake in the template?
** Run the program with different dimX values. For each one, approximate the FLOPS (floating-point operation per second) achieved in computing the SMPV (sparse matrix multiplication). Report FLOPS at different input sizes in a FLOPS. What do you see compared to the peak throughput you report in Lab2?
TODO
** Run the program with dimX=128 and vary nsteps from 100 to 10000. Plot the relative error of the approximation at different nstep. What do you observe?
TODO
** Compare the performance with and without the prefetching in Unified Memory. How is the performance impact? [Optional: using nvprof to get metrics on UM]
TODO
